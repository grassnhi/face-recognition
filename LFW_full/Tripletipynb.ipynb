{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzOj2KKhHQX8"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import accuracy_score\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z7Yy6VOHn8J",
        "outputId": "4c8c31b6-0857-4a71-8104-fb7dcca96bcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (9527, 112, 92, 1)\n",
            "y_train shape: (9527,)\n",
            "x_valid shape: (1059, 112, 92, 1)\n",
            "y_valid shape: (1059,)\n",
            "x_test shape: (2647, 112, 92, 1)\n",
            "y_test shape: (2647,)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import tarfile\n",
        "\n",
        "\n",
        "# Extract LFW dataset if not already extracted\n",
        "if not os.path.exists('lfw'):\n",
        "    with tarfile.open('/content/lfw-funneled.tgz', 'r:gz') as tar:\n",
        "        tar.extractall()\n",
        "\n",
        "# Function to load images and labels from LFW dataset\n",
        "def load_lfw_dataset(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    person_folders = sorted(os.listdir(data_dir))\n",
        "    label_map = {person: idx for idx, person in enumerate(person_folders)}\n",
        "\n",
        "    for person in person_folders:\n",
        "        person_dir = os.path.join(data_dir, person)\n",
        "        if os.path.isdir(person_dir):\n",
        "            for image_file in os.listdir(person_dir):\n",
        "                image_path = os.path.join(person_dir, image_file)\n",
        "                image = load_img(image_path, color_mode='grayscale', target_size=(112, 92))\n",
        "                image = img_to_array(image) / 255.0  # Normalize pixel values\n",
        "                images.append(image)\n",
        "                labels.append(label_map[person])\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load LFW dataset\n",
        "data_dir = 'lfw_funneled'\n",
        "images, labels = load_lfw_dataset(data_dir)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "# Print dataset shapes for verification\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('x_valid shape:', x_valid.shape)\n",
        "print('y_valid shape:', y_valid.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_test shape:', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3zicw6MoWas"
      },
      "outputs": [],
      "source": [
        "def create_triplets(x, y, num_triplets=10000):\n",
        "    triplets = []\n",
        "    labels = []\n",
        "    n_classes = np.max(y) + 1\n",
        "    digit_indices = [np.where(y == i)[0] for i in range(n_classes)]\n",
        "\n",
        "    for _ in range(num_triplets):\n",
        "        # Select anchor\n",
        "        anchor_class = np.random.randint(0, n_classes)\n",
        "\n",
        "        # Check if there are samples in the anchor class\n",
        "        if len(digit_indices[anchor_class]) == 0:\n",
        "            continue\n",
        "\n",
        "        anchor_idx = np.random.choice(digit_indices[anchor_class])\n",
        "        anchor = x[anchor_idx]\n",
        "\n",
        "        # Select positive\n",
        "        positive_idx = np.random.choice(digit_indices[anchor_class])\n",
        "        positive = x[positive_idx]\n",
        "\n",
        "        # Select negative\n",
        "        negative_class = (anchor_class + np.random.randint(1, n_classes)) % n_classes\n",
        "\n",
        "        # Check if there are samples in the negative class\n",
        "        if len(digit_indices[negative_class]) == 0:\n",
        "            continue\n",
        "\n",
        "        negative_idx = np.random.choice(digit_indices[negative_class])\n",
        "        negative = x[negative_idx]\n",
        "\n",
        "        triplets.append([anchor, positive, negative])\n",
        "        labels.append([0])  # Dummy label, not used in training triplet loss\n",
        "\n",
        "    return np.array(triplets), np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ibhgNN_JlCP",
        "outputId": "dd28ef30-46e6-4354-8e66-6866e0a94ceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, 112, 92, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " input_8 (InputLayer)        [(None, 112, 92, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " input_9 (InputLayer)        [(None, 112, 92, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " sequential_4 (Sequential)   (None, 4096)                 2636473   ['input_7[0][0]',             \n",
            "                                                          6          'input_8[0][0]',             \n",
            "                                                                     'input_9[0][0]']             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 12288)                0         ['sequential_4[0][0]',        \n",
            " )                                                                   'sequential_4[1][0]',        \n",
            "                                                                     'sequential_4[2][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 26364736 (100.57 MB)\n",
            "Trainable params: 26364736 (100.57 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "im_rows, im_cols = 112, 92\n",
        "\n",
        "from keras.layers import concatenate\n",
        "\n",
        "# Define base network\n",
        "def build_base_network(input_shape):\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (10, 10), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(128, (7, 7), activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(128, (4, 4), activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(256, (4, 4), activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(4096, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define triplet Siamese network model\n",
        "input_shape = (im_rows, im_cols, 1)\n",
        "base_network = build_base_network(input_shape)\n",
        "\n",
        "input_anchor = Input(shape=input_shape)\n",
        "input_positive = Input(shape=input_shape)\n",
        "input_negative = Input(shape=input_shape)\n",
        "\n",
        "processed_anchor = base_network(input_anchor)\n",
        "processed_positive = base_network(input_positive)\n",
        "processed_negative = base_network(input_negative)\n",
        "\n",
        "# Concatenate outputs\n",
        "concatenated = concatenate([processed_anchor, processed_positive, processed_negative], axis=-1)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=[input_anchor, input_positive, input_negative], outputs=concatenated)\n",
        "\n",
        "# Triplet loss function\n",
        "def triplet_loss(y_true, y_pred, alpha=0.2):\n",
        "    anchor, positive, negative = y_pred[:, 0:4096], y_pred[:, 4096:8192], y_pred[:, 8192:12288]\n",
        "    positive_distance = K.sum(K.square(anchor - positive), axis=-1)\n",
        "    negative_distance = K.sum(K.square(anchor - negative), axis=-1)\n",
        "    return K.sum(K.maximum(0.0, positive_distance - negative_distance + alpha))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss=triplet_loss)\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4t1VcQK8w90",
        "outputId": "cf4433f6-078d-4905-8512-ff558ec5b77a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_triplets shape: (6128, 3, 112, 92, 1)\n",
            "valid_triplets shape: (191, 3, 112, 92, 1)\n"
          ]
        }
      ],
      "source": [
        "# Create triplets for training and validation\n",
        "train_triplets, train_labels = create_triplets(x_train, y_train)\n",
        "valid_triplets, valid_labels = create_triplets(x_valid, y_valid)\n",
        "\n",
        "# Check shapes or print to verify\n",
        "print('train_triplets shape:', train_triplets.shape)\n",
        "print('valid_triplets shape:', valid_triplets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O3pzGs3skJc",
        "outputId": "3b5ba634-54b9-4f27-a542-9eba62f1a470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "48/48 [==============================] - 1440s 30s/step - loss: 5.3362 - val_loss: 1.0067\n",
            "Epoch 2/50\n",
            "48/48 [==============================] - 1427s 30s/step - loss: 2.2351 - val_loss: 0.9223\n",
            "Epoch 3/50\n",
            "48/48 [==============================] - 1460s 30s/step - loss: 1.5016 - val_loss: 0.8282\n",
            "Epoch 4/50\n",
            "36/48 [=====================>........] - ETA: 5:56 - loss: 1.0657"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    [train_triplets[:, 0], train_triplets[:, 1], train_triplets[:, 2]], train_labels,\n",
        "    batch_size=128,\n",
        "    epochs=50,\n",
        "    validation_data=([valid_triplets[:, 0], valid_triplets[:, 1], valid_triplets[:, 2]], valid_labels)\n",
        ")\n",
        "\n",
        "# Evaluate the model if needed\n",
        "# score = model.evaluate([x_test[:, 0], x_test[:, 1], x_test[:, 2]], y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpRLqz4TJtfA"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on test set\n",
        "test_pairs, test_labels = create_pairs(x_test, y_test)\n",
        "score = model.evaluate([test_pairs[:, 0], test_pairs[:, 1]], test_labels)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# Plot training history (accuracy and loss)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMZChl6cfvHY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "def evaluate_triplet_model(model, test_triplets, y_true):\n",
        "    # Predict distances for test triplets\n",
        "    test_distances = model.predict([test_triplets[:, 0], test_triplets[:, 1], test_triplets[:, 2]])\n",
        "\n",
        "    # Calculate distances\n",
        "    anchor_positive_dist = np.linalg.norm(test_distances[:, :4096], axis=1)\n",
        "    anchor_negative_dist = np.linalg.norm(test_distances[:, 4096:8192], axis=1)\n",
        "\n",
        "    # Predictions based on distances\n",
        "    y_pred = (anchor_positive_dist < anchor_negative_dist).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(f'Confusion Matrix:\\n{cm}')\n",
        "\n",
        "    # Classification report\n",
        "    class_report = classification_report(y_true, y_pred)\n",
        "    print(f'Classification Report:\\n{class_report}')\n",
        "\n",
        "    return accuracy, cm, class_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDERX1KCsIKE"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on test data\n",
        "accuracy, conf_matrix, class_report = evaluate_triplet_model(model, test_triplets, y_test)\n",
        "\n",
        "# Optionally, plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "plot_confusion_matrix(conf_matrix, classes=['Not Same', 'Same'], normalize=True, title='Normalized Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(class_report)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}