{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzOj2KKhHQX8"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import accuracy_score\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z7Yy6VOHn8J",
        "outputId": "872bce9f-9d4a-43b8-aec8-a37c853168a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (9527, 112, 92, 1)\n",
            "y_train shape: (9527,)\n",
            "x_valid shape: (1059, 112, 92, 1)\n",
            "y_valid shape: (1059,)\n",
            "x_test shape: (2647, 112, 92, 1)\n",
            "y_test shape: (2647,)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import tarfile\n",
        "\n",
        "\n",
        "# Extract LFW dataset if not already extracted\n",
        "if not os.path.exists('lfw'):\n",
        "    with tarfile.open('/content/lfw-funneled.tgz', 'r:gz') as tar:\n",
        "        tar.extractall()\n",
        "\n",
        "# Function to load images and labels from LFW dataset\n",
        "def load_lfw_dataset(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    person_folders = sorted(os.listdir(data_dir))\n",
        "    label_map = {person: idx for idx, person in enumerate(person_folders)}\n",
        "\n",
        "    for person in person_folders:\n",
        "        person_dir = os.path.join(data_dir, person)\n",
        "        if os.path.isdir(person_dir):\n",
        "            for image_file in os.listdir(person_dir):\n",
        "                image_path = os.path.join(person_dir, image_file)\n",
        "                image = load_img(image_path, color_mode='grayscale', target_size=(112, 92))\n",
        "                image = img_to_array(image) / 255.0  # Normalize pixel values\n",
        "                images.append(image)\n",
        "                labels.append(label_map[person])\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load LFW dataset\n",
        "data_dir = 'lfw_funneled'\n",
        "images, labels = load_lfw_dataset(data_dir)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "# Print dataset shapes for verification\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('x_valid shape:', x_valid.shape)\n",
        "print('y_valid shape:', y_valid.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_test shape:', y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3zicw6MoWas",
        "outputId": "220f34ea-2306-4e1c-e62a-8f4f19c4b7e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 112, 92, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, 112, 92, 1)]         0         []                            \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)   (None, 4096)                 2636473   ['input_3[0][0]',             \n",
            "                                                          6          'input_4[0][0]']             \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)           (None, 1)                    0         ['sequential_1[0][0]',        \n",
            "                                                                     'sequential_1[1][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 26364736 (100.57 MB)\n",
            "Trainable params: 26364736 (100.57 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def create_pairs(x, y):\n",
        "    pairs = []\n",
        "    labels = []\n",
        "    n_classes = np.max(y) + 1\n",
        "    digit_indices = [np.where(y == i)[0] for i in range(n_classes)]\n",
        "\n",
        "    for idx1 in range(len(x)):\n",
        "        x1 = x[idx1]\n",
        "        label1 = y[idx1]\n",
        "\n",
        "        # Positive pair\n",
        "        idx2 = np.random.choice(digit_indices[label1])\n",
        "        x2 = x[idx2]\n",
        "        pairs.append([x1, x2])\n",
        "        labels.append(1)\n",
        "\n",
        "        # Negative pair\n",
        "        label2 = (label1 + np.random.randint(1, n_classes)) % n_classes\n",
        "        if len(digit_indices[label2]) > 0:  # Check if there are samples for negative pair\n",
        "            idx2 = np.random.choice(digit_indices[label2])\n",
        "            x2 = x[idx2]\n",
        "            pairs.append([x1, x2])\n",
        "            labels.append(0)\n",
        "\n",
        "    return np.array(pairs), np.array(labels)\n",
        "\n",
        "\n",
        "def build_base_network(input_shape):\n",
        "    # Define base CNN model to extract features from images\n",
        "    model = Sequential([\n",
        "        Conv2D(64, (10, 10), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(128, (7, 7), activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(128, (4, 4), activation='relu'),\n",
        "        MaxPooling2D(),\n",
        "        Conv2D(256, (4, 4), activation='relu'),\n",
        "        Flatten(),\n",
        "        Dense(4096, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def euclidean_distance(vectors):\n",
        "    # Custom Lambda layer to compute Euclidean distance between two embeddings\n",
        "    x, y = vectors\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "def euclidean_distance_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "# Build Siamese network model\n",
        "im_rows, im_cols = 112, 92\n",
        "input_shape = (im_rows, im_cols, 1)\n",
        "base_network = build_base_network(input_shape)\n",
        "\n",
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        "\n",
        "processed_a = base_network(input_a)\n",
        "processed_b = base_network(input_b)\n",
        "\n",
        "distance = Lambda(euclidean_distance, output_shape=euclidean_distance_output_shape)([processed_a, processed_b])\n",
        "\n",
        "model = Model([input_a, input_b], distance)\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Create pairs for training and validation\n",
        "train_pairs, train_labels = create_pairs(x_train, y_train)\n",
        "valid_pairs, valid_labels = create_pairs(x_valid, y_valid)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ibhgNN_JlCP",
        "outputId": "3bb6d720-00d6-4b1d-d08a-87d0b9cc87f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "134/134 [==============================] - 4462s 33s/step - loss: 2.6789 - accuracy: 0.4307 - val_loss: 5.4738 - val_accuracy: 0.1470\n",
            "Epoch 2/50\n",
            "134/134 [==============================] - 4375s 33s/step - loss: 2.6506 - accuracy: 0.4514 - val_loss: 5.4472 - val_accuracy: 0.1763\n",
            "Epoch 3/50\n",
            "  5/134 [>.............................] - ETA: 1:07:04 - loss: 2.3987 - accuracy: 0.4672"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    [train_pairs[:, 0], train_pairs[:, 1]], train_labels,\n",
        "    batch_size=128,\n",
        "    epochs=50,\n",
        "    validation_data=([valid_pairs[:, 0], valid_pairs[:, 1]], valid_labels)\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpRLqz4TJtfA"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on test set\n",
        "test_pairs, test_labels = create_pairs(x_test, y_test)\n",
        "score = model.evaluate([test_pairs[:, 0], test_pairs[:, 1]], test_labels)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "# Plot training history (accuracy and loss)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMZChl6cfvHY"
      },
      "outputs": [],
      "source": [
        "# Optionally, save the trained model\n",
        "model.save('siamese_network_lfw_model.h5')\n",
        "\n",
        "# Load the trained model\n",
        "loaded_model = load_model('siamese_network_lfw_model.h5', custom_objects={'euclidean_distance': euclidean_distance, 'euclidean_distance_output_shape': euclidean_distance_output_shape})\n",
        "\n",
        "# Use the loaded model to make predictions\n",
        "test_distance = loaded_model.predict([test_pairs[:, 0], test_pairs[:, 1]])\n",
        "y_pred = (test_distance < 0.5).astype(int).reshape(-1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, y_pred)\n",
        "print(\"Loaded model accuracy:\", accuracy)\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "cnf_matrix = confusion_matrix(test_labels, y_pred)\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=['Not Same', 'Same'], title='Confusion matrix, without normalization')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(test_labels, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}